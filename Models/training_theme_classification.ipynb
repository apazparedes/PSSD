{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d6029f-7016-44e8-b210-4c213d42756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29983080-84a7-4979-92a4-c207f1f5c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147b1e51-55cb-4420-a083-5f15ff430594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52e8ec5-dfbd-433f-ae73-4d3a251e8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['texte'], inplace=True)\n",
    "df['texte'] = df['texte'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98cfe78-cd39-451f-9c6a-3e9375930bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_themes = pd.read_csv('Annotations/theme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38312c0-3411-44f3-81a2-635f725fc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_themes, on=\"identifiant\", how=\"left\", suffixes=(\"\", \"_manual\"))\n",
    "df_merged[\"texte_total\"] = df_merged[\"titre\"].fillna(\"\") + \" \" + df_merged[\"texte\"].fillna(\"\")\n",
    "df_merged = df_merged[~df_merged[\"theme\"].isna()]\n",
    "df_merged[\"theme\"] = df_merged[\"theme\"].replace({\n",
    "    \"tribune\": \"analyse\",\n",
    "    \"société\": \"politique\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c800e5c3-2c22-46dd-80a5-bcc0a17d0cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [00:19, 22.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "from tqdm import tqdm\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\").to(device)\n",
    "model.eval()  \n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "for _, row in tqdm(df_merged.iterrows()):\n",
    "    sentence = row['texte_total']\n",
    "    theme = row['theme']\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=False)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        token_embeddings = outputs.last_hidden_state.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    embeddings_dict[sentence] = {\n",
    "        \"embeddings\": token_embeddings, \n",
    "        \"theme\": theme\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab36731c-adbb-4478-9113-dbc70181f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models/theme_token_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6549ebc3-c154-405b-ae56-1471d8775309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfddeae4-7eba-4da6-ba48-156f31fa51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_merged[\"theme\"].value_counts()\n",
    "valid_themes = counts[counts >= 2].index\n",
    "df_filtered = df_merged[df_merged[\"theme\"].isin(valid_themes)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb18d8ec-d580-4928-bb97-c4f3a30c7856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes conservées : ['actualité', 'analyse', 'culture', 'politique']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_filtered[\"theme_encoded\"] = label_encoder.fit_transform(df_filtered[\"theme\"])\n",
    "print(\"Classes conservées :\", list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26ee6726-82de-40a1-937d-88024669d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_filtered[[\"texte_total\", \"theme_encoded\"]],\n",
    "    test_size=0.2,\n",
    "    stratify=df_filtered[\"theme_encoded\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf149795-9ddf-416e-abab-f0a48068dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5ce387-0697-4a85-bcd2-aa1fabb12714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, \"texte_total\"]\n",
    "        label = self.df.loc[idx, \"theme_encoded\"]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)  # correction ici\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bea516ff-7d0e-4e3c-bdc8-04e3cc2f0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer)\n",
    "test_dataset = TextDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,       \n",
    "    pin_memory=True      \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb69427-d705-4b39-aea8-8bcb1d1852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamembertCNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, conv_out_dim=256, hidden_dim=128, num_classes=4):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.backbone = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=conv_out_dim, kernel_size=3, padding=1)\n",
    "        self.relu_conv = nn.ReLU()\n",
    "        self.lstm1 = nn.LSTM(input_size=conv_out_dim, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_dim * 2, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state              \n",
    "        x = sequence_output.permute(0, 2, 1)                     \n",
    "        x = self.conv1d(x)                                       \n",
    "        x = self.relu_conv(x)\n",
    "        x = x.permute(0, 2, 1)                                   \n",
    "        lstm_out1, _ = self.lstm1(x)\n",
    "        relu_out = self.relu(lstm_out1)\n",
    "        lstm_out2, _ = self.lstm2(relu_out)\n",
    "        cls_token_out = lstm_out2[:, 0, :]                       \n",
    "        logits = self.classifier(cls_token_out)                \n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b725098-1412-402e-b797-810517ecb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train_df['theme_encoded'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts) \n",
    "class_weights = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e353420e-8bbf-48d4-82b4-68be923735d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes : 4\n",
      "Valeurs des labels dans le jeu de test : {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(label_encoder.classes_)\n",
    "print(f\"Nombre de classes : {n_classes}\")\n",
    "print(\"Valeurs des labels dans le jeu de test :\", set(test_df[\"theme_encoded\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3813dd5e-84a0-4f33-b4fc-402e0a403688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertCNNLSTMClassifier().to(device)\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.backbone.encoder.layer[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58ff7211-2843-4cc5-936b-8d7b51d8a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:10<04:14, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 — Loss: 1.3876 | Accuracy: 0.3103 | F1-macro: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:21<04:03, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 — Loss: 1.3849 | Accuracy: 0.3103 | F1-macro: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:31<03:51, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 — Loss: 1.3832 | Accuracy: 0.3678 | F1-macro: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:42<03:41, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 — Loss: 1.3803 | Accuracy: 0.5402 | F1-macro: 0.3812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:53<03:33, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 — Loss: 1.3753 | Accuracy: 0.5632 | F1-macro: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [01:03<03:22, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 — Loss: 1.3673 | Accuracy: 0.6322 | F1-macro: 0.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [01:14<03:12, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 — Loss: 1.3539 | Accuracy: 0.6207 | F1-macro: 0.5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [01:25<03:02, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 — Loss: 1.3350 | Accuracy: 0.6552 | F1-macro: 0.6337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [01:36<02:51, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 — Loss: 1.2967 | Accuracy: 0.5977 | F1-macro: 0.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:46<02:40, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 — Loss: 1.2344 | Accuracy: 0.5517 | F1-macro: 0.4784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:57<02:29, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 — Loss: 1.1457 | Accuracy: 0.5632 | F1-macro: 0.5011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [02:07<02:18, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 — Loss: 1.0727 | Accuracy: 0.5977 | F1-macro: 0.5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [02:18<02:08, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 — Loss: 1.0352 | Accuracy: 0.6782 | F1-macro: 0.6516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [02:29<01:58, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 — Loss: 1.0142 | Accuracy: 0.6552 | F1-macro: 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [02:40<01:47, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 — Loss: 0.9155 | Accuracy: 0.6437 | F1-macro: 0.6103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [02:50<01:36, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 — Loss: 0.8375 | Accuracy: 0.6782 | F1-macro: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [03:01<01:25, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 — Loss: 0.7615 | Accuracy: 0.6322 | F1-macro: 0.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [03:12<01:15, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 — Loss: 0.7589 | Accuracy: 0.7241 | F1-macro: 0.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [03:23<01:04, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 — Loss: 0.7151 | Accuracy: 0.6667 | F1-macro: 0.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [03:33<00:53, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 — Loss: 0.6684 | Accuracy: 0.6897 | F1-macro: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [03:44<00:42, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 — Loss: 0.6157 | Accuracy: 0.6552 | F1-macro: 0.6289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [03:55<00:32, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 — Loss: 0.6112 | Accuracy: 0.5862 | F1-macro: 0.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [04:06<00:21, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 — Loss: 0.5493 | Accuracy: 0.6322 | F1-macro: 0.5911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [04:16<00:10, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 — Loss: 0.5085 | Accuracy: 0.7471 | F1-macro: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:27<00:00, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 — Loss: 0.4982 | Accuracy: 0.7011 | F1-macro: 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)  # ← attention, le champ correct ici\n",
    "\n",
    "        logits = model(input_ids, attention_mask)  # [batch, 6]\n",
    "        loss = criterion(logits, labels)           # labels : [batch] (entiers 0–5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {total_loss/len(train_loader):.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | F1-macro: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9d48432-c1f9-47b2-9e3a-3595019cc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Models/camembert_cnn_lstm_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ede50c6-b209-4d48-a253-f8a97e5d8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_theme(text, model, tokenizer, device, label_encoder=None):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs['input_ids'], inputs['attention_mask'])  # shape: [1, 6]\n",
    "\n",
    "    prediction_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    if label_encoder is not None:\n",
    "        prediction_label = label_encoder.inverse_transform([prediction_idx])[0]\n",
    "        return prediction_label, prediction_idx\n",
    "    else:\n",
    "        return prediction_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e4abfa-becb-4fdb-95dc-d8488ff33632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   actualité       0.68      0.91      0.78        23\n",
      "     analyse       0.43      0.27      0.33        11\n",
      "     culture       0.86      0.69      0.77        26\n",
      "   politique       0.68      0.70      0.69        27\n",
      "\n",
      "    accuracy                           0.70        87\n",
      "   macro avg       0.66      0.65      0.64        87\n",
      "weighted avg       0.70      0.70      0.69        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055198a-33fc-450e-b3c3-853872ddbcba",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06245628-ff2a-4d6f-b2ea-707b0c025ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df  \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.df.iloc[idx][\"texte\"]) if pd.notna(self.df.iloc[idx][\"texte\"]) else \"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7120bc0-c3ea-4d00-ba87-3b42958ac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df.merge(df_themes, on = 'identifiant', how = 'left')\n",
    "df_to_predict = df_all[df_all[\"theme\"].isna() & df_all[\"texte\"].notna()].copy()\n",
    "original_indices = df_to_predict.index\n",
    "inference_dataset = InferenceDataset(df_to_predict, tokenizer)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c14360e5-02fb-4905-8b8e-4d914d8975d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [05:22<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(inference_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)            \n",
    "        probs = softmax(logits, dim=1)                       \n",
    "\n",
    "        pred_classes = torch.argmax(probs, dim=1)            \n",
    "        max_probs = torch.max(probs, dim=1).values           \n",
    "\n",
    "        all_preds.extend(pred_classes.cpu().numpy())\n",
    "        all_probs.extend(max_probs.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5a0e6fa-84f5-439f-a6c5-af131cb0b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(original_indices) == len(all_preds), \"Must have equal len keys and value when setting with an iterable\"\n",
    "\n",
    "# 6. Mise à jour de df_all\n",
    "df_all.loc[original_indices, \"theme_pred_encoded\"] = all_preds\n",
    "df_all.loc[original_indices, \"theme_pred\"] = label_encoder.inverse_transform(all_preds)\n",
    "df_all.loc[original_indices, \"confidence\"] = all_probs\n",
    "\n",
    "# 7. Remplissage de la colonne finale\n",
    "df_all[\"theme_final\"] = df_all[\"theme\"].fillna(df_all[\"theme_pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bd9036d-835f-44a9-bbdd-1006bceda068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns=['Unnamed: 0', 'theme', 'theme_pred_encoded', 'theme_pred', 'confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cfebdbd-5431-48d7-9a8b-13c7f9042591",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualité = df_all[df_all['theme_final']=='actualité']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7071fc23-f153-44ce-bfcb-420f7d5e8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualité.to_csv('Data/articles_actualite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916a3609-005e-401d-a5cc-c010d988e71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/onyxia/work/media_sexism_violence_treatment/Models'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
