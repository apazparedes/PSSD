{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6029f-7016-44e8-b210-4c213d42756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29983080-84a7-4979-92a4-c207f1f5c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b1e51-55cb-4420-a083-5f15ff430594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e8ec5-dfbd-433f-ae73-4d3a251e8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['texte'], inplace=True)\n",
    "df['texte'] = df['texte'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98cfe78-cd39-451f-9c6a-3e9375930bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_themes = pd.read_csv('Annotations/theme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38312c0-3411-44f3-81a2-635f725fc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_themes, on=\"identifiant\", how=\"left\", suffixes=(\"\", \"_manual\"))\n",
    "df_merged[\"texte_total\"] = df_merged[\"titre\"].fillna(\"\") + \" \" + df_merged[\"texte\"].fillna(\"\")\n",
    "df_merged = df_merged[~df_merged[\"theme\"].isna()]\n",
    "df_merged[\"theme\"] = df_merged[\"theme\"].replace({\n",
    "    \"tribune\": \"analyse\",\n",
    "    \"société\": \"politique\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800e5c3-2c22-46dd-80a5-bcc0a17d0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "from tqdm import tqdm\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\").to(device)\n",
    "model.eval()  \n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "for _, row in tqdm(df_merged.iterrows()):\n",
    "    sentence = row['texte_total']\n",
    "    theme = row['theme']\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=False)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        token_embeddings = outputs.last_hidden_state.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    embeddings_dict[sentence] = {\n",
    "        \"embeddings\": token_embeddings, \n",
    "        \"theme\": theme\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36731c-adbb-4478-9113-dbc70181f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models/theme_token_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549ebc3-c154-405b-ae56-1471d8775309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddeae4-7eba-4da6-ba48-156f31fa51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_merged[\"theme\"].value_counts()\n",
    "valid_themes = counts[counts >= 2].index\n",
    "df_filtered = df_merged[df_merged[\"theme\"].isin(valid_themes)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18d8ec-d580-4928-bb97-c4f3a30c7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_filtered[\"theme_encoded\"] = label_encoder.fit_transform(df_filtered[\"theme\"])\n",
    "print(\"Classes conservées :\", list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee6726-82de-40a1-937d-88024669d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_filtered[[\"texte_total\", \"theme_encoded\"]],\n",
    "    test_size=0.2,\n",
    "    stratify=df_filtered[\"theme_encoded\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf149795-9ddf-416e-abab-f0a48068dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ce387-0697-4a85-bcd2-aa1fabb12714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, \"texte_total\"]\n",
    "        label = self.df.loc[idx, \"theme_encoded\"]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)  # correction ici\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea516ff-7d0e-4e3c-bdc8-04e3cc2f0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer)\n",
    "test_dataset = TextDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,       \n",
    "    pin_memory=True      \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb69427-d705-4b39-aea8-8bcb1d1852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamembertCNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, conv_out_dim=256, hidden_dim=128, num_classes=4):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.backbone = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=conv_out_dim, kernel_size=3, padding=1)\n",
    "        self.relu_conv = nn.ReLU()\n",
    "        self.lstm1 = nn.LSTM(input_size=conv_out_dim, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_dim * 2, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state              \n",
    "        x = sequence_output.permute(0, 2, 1)                     \n",
    "        x = self.conv1d(x)                                       \n",
    "        x = self.relu_conv(x)\n",
    "        x = x.permute(0, 2, 1)                                   \n",
    "        lstm_out1, _ = self.lstm1(x)\n",
    "        relu_out = self.relu(lstm_out1)\n",
    "        lstm_out2, _ = self.lstm2(relu_out)\n",
    "        cls_token_out = lstm_out2[:, 0, :]                       \n",
    "        logits = self.classifier(cls_token_out)                \n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b725098-1412-402e-b797-810517ecb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train_df['theme_encoded'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts) \n",
    "class_weights = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353420e-8bbf-48d4-82b4-68be923735d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(label_encoder.classes_)\n",
    "print(f\"Nombre de classes : {n_classes}\")\n",
    "print(\"Valeurs des labels dans le jeu de test :\", set(test_df[\"theme_encoded\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813dd5e-84a0-4f33-b4fc-402e0a403688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertCNNLSTMClassifier().to(device)\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.backbone.encoder.layer[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff7211-2843-4cc5-936b-8d7b51d8a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)  \n",
    "\n",
    "        logits = model(input_ids, attention_mask)  \n",
    "        loss = criterion(logits, labels)           \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {total_loss/len(train_loader):.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | F1-macro: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d48432-c1f9-47b2-9e3a-3595019cc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Models/camembert_cnn_lstm_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede50c6-b209-4d48-a253-f8a97e5d8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_theme(text, model, tokenizer, device, label_encoder=None):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs['input_ids'], inputs['attention_mask'])  # shape: [1, 6]\n",
    "\n",
    "    prediction_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    if label_encoder is not None:\n",
    "        prediction_label = label_encoder.inverse_transform([prediction_idx])[0]\n",
    "        return prediction_label, prediction_idx\n",
    "    else:\n",
    "        return prediction_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4abfa-becb-4fdb-95dc-d8488ff33632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055198a-33fc-450e-b3c3-853872ddbcba",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06245628-ff2a-4d6f-b2ea-707b0c025ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df  \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.df.iloc[idx][\"texte\"]) if pd.notna(self.df.iloc[idx][\"texte\"]) else \"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7120bc0-c3ea-4d00-ba87-3b42958ac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df.merge(df_themes, on = 'identifiant', how = 'left')\n",
    "df_to_predict = df_all[df_all[\"theme\"].isna() & df_all[\"texte\"].notna()].copy()\n",
    "original_indices = df_to_predict.index\n",
    "inference_dataset = InferenceDataset(df_to_predict, tokenizer)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14360e5-02fb-4905-8b8e-4d914d8975d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(inference_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)            \n",
    "        probs = softmax(logits, dim=1)                       \n",
    "\n",
    "        pred_classes = torch.argmax(probs, dim=1)            \n",
    "        max_probs = torch.max(probs, dim=1).values           \n",
    "\n",
    "        all_preds.extend(pred_classes.cpu().numpy())\n",
    "        all_probs.extend(max_probs.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0e6fa-84f5-439f-a6c5-af131cb0b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(original_indices) == len(all_preds), \"Must have equal len keys and value when setting with an iterable\"\n",
    "\n",
    "\n",
    "df_all.loc[original_indices, \"theme_pred_encoded\"] = all_preds\n",
    "df_all.loc[original_indices, \"theme_pred\"] = label_encoder.inverse_transform(all_preds)\n",
    "df_all.loc[original_indices, \"confidence\"] = all_probs\n",
    "df_all[\"theme_final\"] = df_all[\"theme\"].fillna(df_all[\"theme_pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9036d-835f-44a9-bbdd-1006bceda068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns=['Unnamed: 0', 'theme', 'theme_pred_encoded', 'theme_pred', 'confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfebdbd-5431-48d7-9a8b-13c7f9042591",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualité = df_all[df_all['theme_final']=='actualité']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071fc23-f153-44ce-bfcb-420f7d5e8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualité.to_csv('Data/articles_actualite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a3609-005e-401d-a5cc-c010d988e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
