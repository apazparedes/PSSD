{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb154f07-f244-445e-b62a-5daddf8462cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1UR_MC8Q5K4JSRnSUX5MQ-sIGPjLLnm9f\n",
      "From (redirected): https://drive.google.com/uc?id=1UR_MC8Q5K4JSRnSUX5MQ-sIGPjLLnm9f&confirm=t&uuid=c7859b70-1121-41a3-a36d-05548203bb16\n",
      "To: /home/onyxia/work/PSSD/Data/data.csv\n",
      "100%|██████████| 363M/363M [00:04<00:00, 87.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "%run Data/downoald_and_cleaning_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d6029f-7016-44e8-b210-4c213d42756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29983080-84a7-4979-92a4-c207f1f5c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147b1e51-55cb-4420-a083-5f15ff430594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52e8ec5-dfbd-433f-ae73-4d3a251e8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['texte'], inplace=True)\n",
    "df['texte'] = df['texte'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98cfe78-cd39-451f-9c6a-3e9375930bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "df_themes = pd.read_csv('Annotations/theme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38312c0-3411-44f3-81a2-635f725fc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_themes, on=\"identifiant\", how=\"left\", suffixes=(\"\", \"_manual\"))\n",
    "df_merged[\"texte_total\"] = df_merged[\"titre\"].fillna(\"\") + \" \" + df_merged[\"texte\"].fillna(\"\")\n",
    "df_merged = df_merged[~df_merged[\"theme\"].isna()]\n",
    "df_merged[\"theme\"] = df_merged[\"theme\"].replace({\n",
    "    \"tribune\": \"analyse\",\n",
    "    \"société\": \"politique\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c800e5c3-2c22-46dd-80a5-bcc0a17d0cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [00:13, 31.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\").to(device)\n",
    "model.eval()  \n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "for _, row in tqdm(df_merged.iterrows()):\n",
    "    sentence = row['texte_total']\n",
    "    theme = row['theme']\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=False)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        token_embeddings = outputs.last_hidden_state.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    embeddings_dict[sentence] = {\n",
    "        \"embeddings\": token_embeddings, \n",
    "        \"theme\": theme\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36731c-adbb-4478-9113-dbc70181f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models/theme_token_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6549ebc3-c154-405b-ae56-1471d8775309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfddeae4-7eba-4da6-ba48-156f31fa51b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes conservées : ['actualité', 'analyse', 'culture', 'politique']\n"
     ]
    }
   ],
   "source": [
    "counts = df_merged[\"theme\"].value_counts()\n",
    "valid_themes = counts[counts >= 2].index\n",
    "df_filtered = df_merged[df_merged[\"theme\"].isin(valid_themes)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18d8ec-d580-4928-bb97-c4f3a30c7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_filtered[\"theme_encoded\"] = label_encoder.fit_transform(df_filtered[\"theme\"])\n",
    "print(\"Classes conservées :\", list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee6726-82de-40a1-937d-88024669d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_filtered[[\"texte_total\", \"theme_encoded\"]],\n",
    "    test_size=0.2,\n",
    "    stratify=df_filtered[\"theme_encoded\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf149795-9ddf-416e-abab-f0a48068dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e5ce387-0697-4a85-bcd2-aa1fabb12714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, \"texte_total\"]\n",
    "        label = self.df.loc[idx, \"theme_encoded\"]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)  # correction ici\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea516ff-7d0e-4e3c-bdc8-04e3cc2f0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer)\n",
    "test_dataset = TextDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,       \n",
    "    pin_memory=True      \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb69427-d705-4b39-aea8-8bcb1d1852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamembertCNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, conv_out_dim=256, hidden_dim=128, num_classes=4):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.backbone = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=conv_out_dim, kernel_size=3, padding=1)\n",
    "        self.relu_conv = nn.ReLU()\n",
    "        self.lstm1 = nn.LSTM(input_size=conv_out_dim, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_dim * 2, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state              \n",
    "        x = sequence_output.permute(0, 2, 1)                     \n",
    "        x = self.conv1d(x)                                       \n",
    "        x = self.relu_conv(x)\n",
    "        x = x.permute(0, 2, 1)                                   \n",
    "        lstm_out1, _ = self.lstm1(x)\n",
    "        relu_out = self.relu(lstm_out1)\n",
    "        lstm_out2, _ = self.lstm2(relu_out)\n",
    "        cls_token_out = lstm_out2[:, 0, :]                       \n",
    "        logits = self.classifier(cls_token_out)                \n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b725098-1412-402e-b797-810517ecb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train_df['theme_encoded'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts) \n",
    "class_weights = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e353420e-8bbf-48d4-82b4-68be923735d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes : 4\n",
      "Valeurs des labels dans le jeu de test : {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(label_encoder.classes_)\n",
    "print(f\"Nombre de classes : {n_classes}\")\n",
    "print(\"Valeurs des labels dans le jeu de test :\", set(test_df[\"theme_encoded\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3813dd5e-84a0-4f33-b4fc-402e0a403688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertCNNLSTMClassifier().to(device)\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.backbone.encoder.layer[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ff7211-2843-4cc5-936b-8d7b51d8a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:07<02:54,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 — Loss: 1.3868 | Accuracy: 0.1264 | F1-macro: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:14<02:44,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 — Loss: 1.3853 | Accuracy: 0.1264 | F1-macro: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:21<02:37,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 — Loss: 1.3825 | Accuracy: 0.1264 | F1-macro: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:28<02:31,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 — Loss: 1.3790 | Accuracy: 0.3908 | F1-macro: 0.3103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:35<02:23,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 — Loss: 1.3743 | Accuracy: 0.5747 | F1-macro: 0.5216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:43<02:17,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 — Loss: 1.3660 | Accuracy: 0.5862 | F1-macro: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:50<02:09,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 — Loss: 1.3537 | Accuracy: 0.5977 | F1-macro: 0.5128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [00:57<02:02,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 — Loss: 1.3338 | Accuracy: 0.5747 | F1-macro: 0.4898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [01:04<01:54,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 — Loss: 1.2913 | Accuracy: 0.4713 | F1-macro: 0.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:11<01:47,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 — Loss: 1.2336 | Accuracy: 0.4828 | F1-macro: 0.3264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:19<01:40,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 — Loss: 1.1525 | Accuracy: 0.5172 | F1-macro: 0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [01:26<01:33,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 — Loss: 1.0662 | Accuracy: 0.5977 | F1-macro: 0.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [01:33<01:26,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 — Loss: 1.0061 | Accuracy: 0.5977 | F1-macro: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [01:40<01:19,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 — Loss: 0.8852 | Accuracy: 0.6092 | F1-macro: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [01:48<01:12,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 — Loss: 0.8447 | Accuracy: 0.6552 | F1-macro: 0.6231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [01:55<01:05,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 — Loss: 0.7813 | Accuracy: 0.6437 | F1-macro: 0.6193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [02:02<00:57,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 — Loss: 0.7528 | Accuracy: 0.6322 | F1-macro: 0.5821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [02:09<00:50,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 — Loss: 0.7389 | Accuracy: 0.6782 | F1-macro: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [02:16<00:43,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 — Loss: 0.6976 | Accuracy: 0.5977 | F1-macro: 0.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [02:24<00:36,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 — Loss: 0.6045 | Accuracy: 0.7011 | F1-macro: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [02:31<00:28,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 — Loss: 0.5773 | Accuracy: 0.6552 | F1-macro: 0.6054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [02:38<00:21,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 — Loss: 0.5869 | Accuracy: 0.6782 | F1-macro: 0.6597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [02:46<00:14,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 — Loss: 0.5306 | Accuracy: 0.6897 | F1-macro: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [02:53<00:07,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 — Loss: 0.4961 | Accuracy: 0.7126 | F1-macro: 0.6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:01<00:00,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 — Loss: 0.5448 | Accuracy: 0.7241 | F1-macro: 0.6657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)  # ← attention, le champ correct ici\n",
    "\n",
    "        logits = model(input_ids, attention_mask)  # [batch, 6]\n",
    "        loss = criterion(logits, labels)           # labels : [batch] (entiers 0–5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {total_loss/len(train_loader):.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | F1-macro: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9d48432-c1f9-47b2-9e3a-3595019cc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Models/camembert_cnn_lstm_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ede50c6-b209-4d48-a253-f8a97e5d8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_theme(text, model, tokenizer, device, label_encoder=None):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs['input_ids'], inputs['attention_mask'])  # shape: [1, 6]\n",
    "\n",
    "    prediction_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    if label_encoder is not None:\n",
    "        prediction_label = label_encoder.inverse_transform([prediction_idx])[0]\n",
    "        return prediction_label, prediction_idx\n",
    "    else:\n",
    "        return prediction_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80e4abfa-becb-4fdb-95dc-d8488ff33632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   actualité       0.71      0.87      0.78        23\n",
      "     analyse       0.60      0.27      0.38        11\n",
      "     culture       0.86      0.73      0.79        26\n",
      "   politique       0.66      0.78      0.71        27\n",
      "\n",
      "    accuracy                           0.72        87\n",
      "   macro avg       0.71      0.66      0.67        87\n",
      "weighted avg       0.73      0.72      0.71        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055198a-33fc-450e-b3c3-853872ddbcba",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06245628-ff2a-4d6f-b2ea-707b0c025ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Forcer la conversion en string et remplacer les NaN\n",
    "        text = str(self.df.loc[idx, \"texte\"]) if pd.notna(self.df.loc[idx, \"texte\"]) else \"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7120bc0-c3ea-4d00-ba87-3b42958ac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/data_clean.csv')\n",
    "df_all = df.merge(df_themes, on = 'identifiant', how = 'left')\n",
    "df_to_predict = df_all[df_all['theme'].isna() & df_all['texte'].notna()].copy()\n",
    "df_to_predict = df_to_predict.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9121d5cf-4ddc-4a7c-aa48-8c1034a514ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = InferenceDataset(df_to_predict, tokenizer)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5a0e6fa-84f5-439f-a6c5-af131cb0b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_to_predict[\"index\"], \"theme_pred_encoded\"] = all_preds\n",
    "df_all.loc[df_to_predict[\"index\"], \"theme_pred\"] = label_encoder.inverse_transform(all_preds)\n",
    "df_all.loc[df_to_predict[\"index\"], \"confidence\"] = all_probs\n",
    "\n",
    "df_all[\"theme_final\"] = df_all[\"theme\"].fillna(df_all[\"theme_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aced732a-c99a-4633-91d1-0bc9f066983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [07:46<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(inference_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)            \n",
    "        probs = softmax(logits, dim=1)                       \n",
    "\n",
    "        pred_classes = torch.argmax(probs, dim=1)            \n",
    "        max_probs = torch.max(probs, dim=1).values           \n",
    "\n",
    "        all_preds.extend(pred_classes.cpu().numpy())\n",
    "        all_probs.extend(max_probs.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bd9036d-835f-44a9-bbdd-1006bceda068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns=['Unnamed: 0', 'theme', 'theme_pred_encoded', 'theme_pred', 'confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4cfebdbd-5431-48d7-9a8b-13c7f9042591",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualité = df_all[df_all['theme_final']=='actualité']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7071fc23-f153-44ce-bfcb-420f7d5e8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualité.to_csv('Data/articles_actualite.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
