{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d6029f-7016-44e8-b210-4c213d42756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29983080-84a7-4979-92a4-c207f1f5c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb154f07-f244-445e-b62a-5daddf8462cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1UR_MC8Q5K4JSRnSUX5MQ-sIGPjLLnm9f\n",
      "From (redirected): https://drive.google.com/uc?id=1UR_MC8Q5K4JSRnSUX5MQ-sIGPjLLnm9f&confirm=t&uuid=1ba44d0c-ff34-4622-a244-3fb0225dd70d\n",
      "To: /home/onyxia/work/PSSD/Data/data.csv\n",
      "100%|██████████| 363M/363M [00:09<00:00, 39.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "%run downoald_and_cleaning_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147b1e51-55cb-4420-a083-5f15ff430594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52e8ec5-dfbd-433f-ae73-4d3a251e8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['texte'], inplace=True)\n",
    "df['texte'] = df['texte'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98cfe78-cd39-451f-9c6a-3e9375930bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "df_themes = pd.read_csv('Annotations/theme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38312c0-3411-44f3-81a2-635f725fc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_themes, on=\"identifiant\", how=\"left\", suffixes=(\"\", \"_manual\"))\n",
    "df_merged[\"texte_total\"] = df_merged[\"titre\"].fillna(\"\") + \" \" + df_merged[\"texte\"].fillna(\"\")\n",
    "df_merged = df_merged[~df_merged[\"theme\"].isna()]\n",
    "df_merged[\"theme\"] = df_merged[\"theme\"].replace({\n",
    "    \"tribune\": \"analyse\",\n",
    "    \"société\": \"politique\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee53779e-7829-48a5-8126-6816c6e8eeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>identifiant</th>\n",
       "      <th>journal_clean</th>\n",
       "      <th>titre</th>\n",
       "      <th>annee</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>texte</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Unnamed: 0_manual</th>\n",
       "      <th>theme</th>\n",
       "      <th>texte_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>391</td>\n",
       "      <td>beb54101bece711668d64dfe5176bc2f38444b30eb9c31...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Suspect en garde à vue</td>\n",
       "      <td>1997</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>l'époux d'une femme tuée de 18 coups de coutea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.0</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Suspect en garde à vue l'époux d'une femme tué...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>432</td>\n",
       "      <td>efee09cde26fba5704002a3180ab0bf7f2f711dbff957d...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Rennes : nouveau meurtre</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>« ici, samedi 6 heures, une femme de 38 ans as...</td>\n",
       "      <td>violence, meurtre, rennes, femme, samedi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Rennes : nouveau meurtre « ici, samedi 6 heure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>433</td>\n",
       "      <td>d183794139b099c8c366eb2482b740f413f22d62bb7d6d...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Une femme médecin assassinée</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>- une femme de 60 ans, médecin allergologue, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Une femme médecin assassinée - une femme de 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>434</td>\n",
       "      <td>00627f5991ec8312f034b90a05650e755e28a6a8109170...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Le fils du médecin interpellé</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>- le fils d'une femme médecin, assassinée chez...</td>\n",
       "      <td>fils</td>\n",
       "      <td>2.0</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Le fils du médecin interpellé - le fils d'une ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>435</td>\n",
       "      <td>965556384a9f3ab74807d96fda6d5802b3f4b9adb93e31...</td>\n",
       "      <td>Libération</td>\n",
       "      <td>Les chantiers de la justice (4): le juge uniqu...</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>le 15 janvier, la garde des sceaux présentait ...</td>\n",
       "      <td>réforme, chantiers, guigou, justice, juge, eli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>politique</td>\n",
       "      <td>Les chantiers de la justice (4): le juge uniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11668</th>\n",
       "      <td>79742</td>\n",
       "      <td>5c3187c3c5ce0d6cd23fc45fdf9591b221521dce48c3e4...</td>\n",
       "      <td>Le Nouvel Obs</td>\n",
       "      <td>Comment le terme de « narchomicide » a remplac...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>remplaçant la notion de « règlement de comptes...</td>\n",
       "      <td>notion, règlement, narchomicide, marseille, co...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>politique</td>\n",
       "      <td>Comment le terme de « narchomicide » a remplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11689</th>\n",
       "      <td>79836</td>\n",
       "      <td>f55d1f12e7282aee5e11bb4dee7a7b6757fa0b0c4c1ee6...</td>\n",
       "      <td>Le Monde</td>\n",
       "      <td>Cécile van de Velde, sociologue : « La montée ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>spécialiste du « devenir adulte » et de l’étud...</td>\n",
       "      <td>velde, solitude, montée, dernières, jeunesse, ...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>analyse</td>\n",
       "      <td>Cécile van de Velde, sociologue : « La montée ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11695</th>\n",
       "      <td>79876</td>\n",
       "      <td>3f3b62241755de4609d7b430ecd9c7c8243aecee7a4667...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>«Ils m'ont violée en groupe pendant cinq jours...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>ce 11 octobre est célébrée la 12e édition de l...</td>\n",
       "      <td>travers, femmes, jours, jeunes, filles, violée...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>analyse</td>\n",
       "      <td>«Ils m'ont violée en groupe pendant cinq jours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11921</th>\n",
       "      <td>81749</td>\n",
       "      <td>bdc27a8afcc44555d82f641e19229cf4f6f5e817431f56...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Violences : une femme tuée par un proche toute...</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>«la maison reste l’endroit le plus dangereux» ...</td>\n",
       "      <td>violences, monde, minutes, femmes, l’onu, alar...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>analyse</td>\n",
       "      <td>Violences : une femme tuée par un proche toute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952</th>\n",
       "      <td>81968</td>\n",
       "      <td>a588f818181d16971d562b130ea9a8e8e787dfc6967cc6...</td>\n",
       "      <td>Le Nouvel Obs</td>\n",
       "      <td>« Rabia » : Megan Northam lève le voile</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>son enthousiasme ravageur rappelle que sa carr...</td>\n",
       "      <td>promo, rabia, megan, northam, compte</td>\n",
       "      <td>281.0</td>\n",
       "      <td>culture</td>\n",
       "      <td>« Rabia » : Megan Northam lève le voile son en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                        identifiant  \\\n",
       "79            391  beb54101bece711668d64dfe5176bc2f38444b30eb9c31...   \n",
       "94            432  efee09cde26fba5704002a3180ab0bf7f2f711dbff957d...   \n",
       "95            433  d183794139b099c8c366eb2482b740f413f22d62bb7d6d...   \n",
       "96            434  00627f5991ec8312f034b90a05650e755e28a6a8109170...   \n",
       "97            435  965556384a9f3ab74807d96fda6d5802b3f4b9adb93e31...   \n",
       "...           ...                                                ...   \n",
       "11668       79742  5c3187c3c5ce0d6cd23fc45fdf9591b221521dce48c3e4...   \n",
       "11689       79836  f55d1f12e7282aee5e11bb4dee7a7b6757fa0b0c4c1ee6...   \n",
       "11695       79876  3f3b62241755de4609d7b430ecd9c7c8243aecee7a4667...   \n",
       "11921       81749  bdc27a8afcc44555d82f641e19229cf4f6f5e817431f56...   \n",
       "11952       81968  a588f818181d16971d562b130ea9a8e8e787dfc6967cc6...   \n",
       "\n",
       "       journal_clean                                              titre  \\\n",
       "79         Le Figaro                             Suspect en garde à vue   \n",
       "94         Le Figaro                           Rennes : nouveau meurtre   \n",
       "95         Le Figaro                       Une femme médecin assassinée   \n",
       "96         Le Figaro                      Le fils du médecin interpellé   \n",
       "97        Libération  Les chantiers de la justice (4): le juge uniqu...   \n",
       "...              ...                                                ...   \n",
       "11668  Le Nouvel Obs  Comment le terme de « narchomicide » a remplac...   \n",
       "11689       Le Monde  Cécile van de Velde, sociologue : « La montée ...   \n",
       "11695      Le Figaro  «Ils m'ont violée en groupe pendant cinq jours...   \n",
       "11921      Le Figaro  Violences : une femme tuée par un proche toute...   \n",
       "11952  Le Nouvel Obs            « Rabia » : Megan Northam lève le voile   \n",
       "\n",
       "       annee  mois  jour                                              texte  \\\n",
       "79      1997     8    25  l'époux d'une femme tuée de 18 coups de coutea...   \n",
       "94      1998     1    19  « ici, samedi 6 heures, une femme de 38 ans as...   \n",
       "95      1998     1    21  - une femme de 60 ans, médecin allergologue, a...   \n",
       "96      1998     1    22  - le fils d'une femme médecin, assassinée chez...   \n",
       "97      1998     1    23  le 15 janvier, la garde des sceaux présentait ...   \n",
       "...      ...   ...   ...                                                ...   \n",
       "11668   2024    10     8  remplaçant la notion de « règlement de comptes...   \n",
       "11689   2024    10    10  spécialiste du « devenir adulte » et de l’étud...   \n",
       "11695   2024    10    11  ce 11 octobre est célébrée la 12e édition de l...   \n",
       "11921   2024    11    25  «la maison reste l’endroit le plus dangereux» ...   \n",
       "11952   2024    11    29  son enthousiasme ravageur rappelle que sa carr...   \n",
       "\n",
       "                                                keywords  Unnamed: 0_manual  \\\n",
       "79                                                   NaN              209.0   \n",
       "94              violence, meurtre, rennes, femme, samedi                0.0   \n",
       "95                                                   NaN                1.0   \n",
       "96                                                  fils                2.0   \n",
       "97     réforme, chantiers, guigou, justice, juge, eli...                3.0   \n",
       "...                                                  ...                ...   \n",
       "11668  notion, règlement, narchomicide, marseille, co...              329.0   \n",
       "11689  velde, solitude, montée, dernières, jeunesse, ...              302.0   \n",
       "11695  travers, femmes, jours, jeunes, filles, violée...              374.0   \n",
       "11921  violences, monde, minutes, femmes, l’onu, alar...              343.0   \n",
       "11952               promo, rabia, megan, northam, compte              281.0   \n",
       "\n",
       "           theme                                        texte_total  \n",
       "79     actualité  Suspect en garde à vue l'époux d'une femme tué...  \n",
       "94     actualité  Rennes : nouveau meurtre « ici, samedi 6 heure...  \n",
       "95     actualité  Une femme médecin assassinée - une femme de 60...  \n",
       "96     actualité  Le fils du médecin interpellé - le fils d'une ...  \n",
       "97     politique  Les chantiers de la justice (4): le juge uniqu...  \n",
       "...          ...                                                ...  \n",
       "11668  politique  Comment le terme de « narchomicide » a remplac...  \n",
       "11689    analyse  Cécile van de Velde, sociologue : « La montée ...  \n",
       "11695    analyse  «Ils m'ont violée en groupe pendant cinq jours...  \n",
       "11921    analyse  Violences : une femme tuée par un proche toute...  \n",
       "11952    culture  « Rabia » : Megan Northam lève le voile son en...  \n",
       "\n",
       "[390 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c800e5c3-2c22-46dd-80a5-bcc0a17d0cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [00:11, 32.79it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\").to(device)\n",
    "model.eval()  \n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "\n",
    "for _, row in tqdm(df_merged.iterrows()):\n",
    "    sentence = row['texte_total']\n",
    "    theme = row['theme']\n",
    "    \n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=False)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        token_embeddings = outputs.last_hidden_state.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    embeddings_dict[sentence] = {\n",
    "        \"embeddings\": token_embeddings, \n",
    "        \"theme\": theme\n",
    "    }\n",
    "\n",
    "\n",
    "with open(\"themeed_token_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6549ebc3-c154-405b-ae56-1471d8775309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_merged.drop('Unnamed: 0_manual', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae83b02-8c75-4850-8290-f57fa6c7e487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifiant</th>\n",
       "      <th>journal_clean</th>\n",
       "      <th>titre</th>\n",
       "      <th>annee</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>texte</th>\n",
       "      <th>keywords</th>\n",
       "      <th>theme</th>\n",
       "      <th>texte_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>beb54101bece711668d64dfe5176bc2f38444b30eb9c31...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Suspect en garde à vue</td>\n",
       "      <td>1997</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>l'époux d'une femme tuée de 18 coups de coutea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Suspect en garde à vue l'époux d'une femme tué...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>efee09cde26fba5704002a3180ab0bf7f2f711dbff957d...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Rennes : nouveau meurtre</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>« ici, samedi 6 heures, une femme de 38 ans as...</td>\n",
       "      <td>violence, meurtre, rennes, femme, samedi</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Rennes : nouveau meurtre « ici, samedi 6 heure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>d183794139b099c8c366eb2482b740f413f22d62bb7d6d...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Une femme médecin assassinée</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>- une femme de 60 ans, médecin allergologue, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Une femme médecin assassinée - une femme de 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>00627f5991ec8312f034b90a05650e755e28a6a8109170...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Le fils du médecin interpellé</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>- le fils d'une femme médecin, assassinée chez...</td>\n",
       "      <td>fils</td>\n",
       "      <td>actualité</td>\n",
       "      <td>Le fils du médecin interpellé - le fils d'une ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>965556384a9f3ab74807d96fda6d5802b3f4b9adb93e31...</td>\n",
       "      <td>Libération</td>\n",
       "      <td>Les chantiers de la justice (4): le juge uniqu...</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>le 15 janvier, la garde des sceaux présentait ...</td>\n",
       "      <td>réforme, chantiers, guigou, justice, juge, eli...</td>\n",
       "      <td>politique</td>\n",
       "      <td>Les chantiers de la justice (4): le juge uniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11668</th>\n",
       "      <td>5c3187c3c5ce0d6cd23fc45fdf9591b221521dce48c3e4...</td>\n",
       "      <td>Le Nouvel Obs</td>\n",
       "      <td>Comment le terme de « narchomicide » a remplac...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>remplaçant la notion de « règlement de comptes...</td>\n",
       "      <td>notion, règlement, narchomicide, marseille, co...</td>\n",
       "      <td>politique</td>\n",
       "      <td>Comment le terme de « narchomicide » a remplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11689</th>\n",
       "      <td>f55d1f12e7282aee5e11bb4dee7a7b6757fa0b0c4c1ee6...</td>\n",
       "      <td>Le Monde</td>\n",
       "      <td>Cécile van de Velde, sociologue : « La montée ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>spécialiste du « devenir adulte » et de l’étud...</td>\n",
       "      <td>velde, solitude, montée, dernières, jeunesse, ...</td>\n",
       "      <td>analyse</td>\n",
       "      <td>Cécile van de Velde, sociologue : « La montée ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11695</th>\n",
       "      <td>3f3b62241755de4609d7b430ecd9c7c8243aecee7a4667...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>«Ils m'ont violée en groupe pendant cinq jours...</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>ce 11 octobre est célébrée la 12e édition de l...</td>\n",
       "      <td>travers, femmes, jours, jeunes, filles, violée...</td>\n",
       "      <td>analyse</td>\n",
       "      <td>«Ils m'ont violée en groupe pendant cinq jours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11921</th>\n",
       "      <td>bdc27a8afcc44555d82f641e19229cf4f6f5e817431f56...</td>\n",
       "      <td>Le Figaro</td>\n",
       "      <td>Violences : une femme tuée par un proche toute...</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>«la maison reste l’endroit le plus dangereux» ...</td>\n",
       "      <td>violences, monde, minutes, femmes, l’onu, alar...</td>\n",
       "      <td>analyse</td>\n",
       "      <td>Violences : une femme tuée par un proche toute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952</th>\n",
       "      <td>a588f818181d16971d562b130ea9a8e8e787dfc6967cc6...</td>\n",
       "      <td>Le Nouvel Obs</td>\n",
       "      <td>« Rabia » : Megan Northam lève le voile</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>son enthousiasme ravageur rappelle que sa carr...</td>\n",
       "      <td>promo, rabia, megan, northam, compte</td>\n",
       "      <td>culture</td>\n",
       "      <td>« Rabia » : Megan Northam lève le voile son en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             identifiant  journal_clean  \\\n",
       "79     beb54101bece711668d64dfe5176bc2f38444b30eb9c31...      Le Figaro   \n",
       "94     efee09cde26fba5704002a3180ab0bf7f2f711dbff957d...      Le Figaro   \n",
       "95     d183794139b099c8c366eb2482b740f413f22d62bb7d6d...      Le Figaro   \n",
       "96     00627f5991ec8312f034b90a05650e755e28a6a8109170...      Le Figaro   \n",
       "97     965556384a9f3ab74807d96fda6d5802b3f4b9adb93e31...     Libération   \n",
       "...                                                  ...            ...   \n",
       "11668  5c3187c3c5ce0d6cd23fc45fdf9591b221521dce48c3e4...  Le Nouvel Obs   \n",
       "11689  f55d1f12e7282aee5e11bb4dee7a7b6757fa0b0c4c1ee6...       Le Monde   \n",
       "11695  3f3b62241755de4609d7b430ecd9c7c8243aecee7a4667...      Le Figaro   \n",
       "11921  bdc27a8afcc44555d82f641e19229cf4f6f5e817431f56...      Le Figaro   \n",
       "11952  a588f818181d16971d562b130ea9a8e8e787dfc6967cc6...  Le Nouvel Obs   \n",
       "\n",
       "                                                   titre  annee  mois  jour  \\\n",
       "79                                Suspect en garde à vue   1997     8    25   \n",
       "94                              Rennes : nouveau meurtre   1998     1    19   \n",
       "95                          Une femme médecin assassinée   1998     1    21   \n",
       "96                         Le fils du médecin interpellé   1998     1    22   \n",
       "97     Les chantiers de la justice (4): le juge uniqu...   1998     1    23   \n",
       "...                                                  ...    ...   ...   ...   \n",
       "11668  Comment le terme de « narchomicide » a remplac...   2024    10     8   \n",
       "11689  Cécile van de Velde, sociologue : « La montée ...   2024    10    10   \n",
       "11695  «Ils m'ont violée en groupe pendant cinq jours...   2024    10    11   \n",
       "11921  Violences : une femme tuée par un proche toute...   2024    11    25   \n",
       "11952            « Rabia » : Megan Northam lève le voile   2024    11    29   \n",
       "\n",
       "                                                   texte  \\\n",
       "79     l'époux d'une femme tuée de 18 coups de coutea...   \n",
       "94     « ici, samedi 6 heures, une femme de 38 ans as...   \n",
       "95     - une femme de 60 ans, médecin allergologue, a...   \n",
       "96     - le fils d'une femme médecin, assassinée chez...   \n",
       "97     le 15 janvier, la garde des sceaux présentait ...   \n",
       "...                                                  ...   \n",
       "11668  remplaçant la notion de « règlement de comptes...   \n",
       "11689  spécialiste du « devenir adulte » et de l’étud...   \n",
       "11695  ce 11 octobre est célébrée la 12e édition de l...   \n",
       "11921  «la maison reste l’endroit le plus dangereux» ...   \n",
       "11952  son enthousiasme ravageur rappelle que sa carr...   \n",
       "\n",
       "                                                keywords      theme  \\\n",
       "79                                                   NaN  actualité   \n",
       "94              violence, meurtre, rennes, femme, samedi  actualité   \n",
       "95                                                   NaN  actualité   \n",
       "96                                                  fils  actualité   \n",
       "97     réforme, chantiers, guigou, justice, juge, eli...  politique   \n",
       "...                                                  ...        ...   \n",
       "11668  notion, règlement, narchomicide, marseille, co...  politique   \n",
       "11689  velde, solitude, montée, dernières, jeunesse, ...    analyse   \n",
       "11695  travers, femmes, jours, jeunes, filles, violée...    analyse   \n",
       "11921  violences, monde, minutes, femmes, l’onu, alar...    analyse   \n",
       "11952               promo, rabia, megan, northam, compte    culture   \n",
       "\n",
       "                                             texte_total  \n",
       "79     Suspect en garde à vue l'époux d'une femme tué...  \n",
       "94     Rennes : nouveau meurtre « ici, samedi 6 heure...  \n",
       "95     Une femme médecin assassinée - une femme de 60...  \n",
       "96     Le fils du médecin interpellé - le fils d'une ...  \n",
       "97     Les chantiers de la justice (4): le juge uniqu...  \n",
       "...                                                  ...  \n",
       "11668  Comment le terme de « narchomicide » a remplac...  \n",
       "11689  Cécile van de Velde, sociologue : « La montée ...  \n",
       "11695  «Ils m'ont violée en groupe pendant cinq jours...  \n",
       "11921  Violences : une femme tuée par un proche toute...  \n",
       "11952  « Rabia » : Megan Northam lève le voile son en...  \n",
       "\n",
       "[390 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911c82d6-c594-42ef-aeab-86344d8c571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda66cc3-bf46-4c3f-8c7c-26eb82244ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_merged[\"theme_encoded\"] = label_encoder.fit_transform(df_merged[\"theme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfddeae4-7eba-4da6-ba48-156f31fa51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df_merged[[\"texte_total\", \"theme_encoded\"]],\n",
    "    test_size=0.2,\n",
    "    stratify=df_merged[\"theme_encoded\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e5ce387-0697-4a85-bcd2-aa1fabb12714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, \"texte_total\"]\n",
    "        label = self.df.loc[idx, \"theme_encoded\"]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)  # correction ici\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea516ff-7d0e-4e3c-bdc8-04e3cc2f0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer)\n",
    "test_dataset = TextDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,       \n",
    "    pin_memory=True      \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb69427-d705-4b39-aea8-8bcb1d1852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import CamembertModel\n",
    "\n",
    "class CamembertCNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, conv_out_dim=256, hidden_dim=128, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.backbone = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        \n",
    "        # On freeze CamemBERT\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=768, out_channels=conv_out_dim, kernel_size=3, padding=1)\n",
    "        self.relu_conv = nn.ReLU()\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=conv_out_dim, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_dim * 2, hidden_size=hidden_dim,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Classification multi-classe (logits de taille [batch, num_classes])\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state              # [batch, seq_len, 768]\n",
    "        x = sequence_output.permute(0, 2, 1)                     # [batch, 768, seq_len]\n",
    "        x = self.conv1d(x)                                       # [batch, conv_out_dim, seq_len]\n",
    "        x = self.relu_conv(x)\n",
    "        x = x.permute(0, 2, 1)                                   # [batch, seq_len, conv_out_dim]\n",
    "        \n",
    "        lstm_out1, _ = self.lstm1(x)\n",
    "        relu_out = self.relu(lstm_out1)\n",
    "        lstm_out2, _ = self.lstm2(relu_out)\n",
    "\n",
    "        cls_token_out = lstm_out2[:, 0, :]                       # On prend le 1er token\n",
    "        logits = self.classifier(cls_token_out)                 # [batch, num_classes]\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b725098-1412-402e-b797-810517ecb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On compte le nombre d'occurrences de chaque classe\n",
    "class_counts = train_df['theme_encoded'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)  # normalisation\n",
    "\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Fonction de perte avec pondération par classe\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3813dd5e-84a0-4f33-b4fc-402e0a403688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertCNNLSTMClassifier().to(device)\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# we only unfreeze the last layer of camembert\n",
    "for param in model.backbone.encoder.layer[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ff7211-2843-4cc5-936b-8d7b51d8a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:07<02:49,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 — Loss: 1.3872 | Accuracy: 0.2692 | F1-macro: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:13<02:35,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 — Loss: 1.3852 | Accuracy: 0.2692 | F1-macro: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:20<02:26,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 — Loss: 1.3831 | Accuracy: 0.3333 | F1-macro: 0.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:26<02:20,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 — Loss: 1.3807 | Accuracy: 0.3590 | F1-macro: 0.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:33<02:12,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 — Loss: 1.3777 | Accuracy: 0.4359 | F1-macro: 0.2914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:39<02:05,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 — Loss: 1.3725 | Accuracy: 0.5000 | F1-macro: 0.3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:46<01:58,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 — Loss: 1.3649 | Accuracy: 0.5256 | F1-macro: 0.3791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [00:52<01:50,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 — Loss: 1.3543 | Accuracy: 0.5128 | F1-macro: 0.3715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [00:59<01:44,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 — Loss: 1.3354 | Accuracy: 0.5897 | F1-macro: 0.5220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:06<01:38,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 — Loss: 1.3076 | Accuracy: 0.6410 | F1-macro: 0.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:12<01:32,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 — Loss: 1.2610 | Accuracy: 0.6154 | F1-macro: 0.5466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [01:19<01:25,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 — Loss: 1.1842 | Accuracy: 0.6026 | F1-macro: 0.4792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [01:26<01:19,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 — Loss: 1.0861 | Accuracy: 0.6410 | F1-macro: 0.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [01:32<01:12,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 — Loss: 0.9817 | Accuracy: 0.6538 | F1-macro: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [01:39<01:06,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 — Loss: 0.8906 | Accuracy: 0.5897 | F1-macro: 0.5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [01:45<00:59,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 — Loss: 0.8264 | Accuracy: 0.6154 | F1-macro: 0.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [01:52<00:52,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 — Loss: 0.8441 | Accuracy: 0.6154 | F1-macro: 0.5859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [01:59<00:46,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 — Loss: 0.7600 | Accuracy: 0.6154 | F1-macro: 0.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [02:05<00:39,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 — Loss: 0.6933 | Accuracy: 0.6667 | F1-macro: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [02:12<00:33,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 — Loss: 0.6643 | Accuracy: 0.6410 | F1-macro: 0.6229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [02:19<00:26,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 — Loss: 0.5926 | Accuracy: 0.6923 | F1-macro: 0.6645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [02:25<00:20,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 — Loss: 0.5384 | Accuracy: 0.6795 | F1-macro: 0.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [02:32<00:13,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 — Loss: 0.5123 | Accuracy: 0.6538 | F1-macro: 0.6322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [02:39<00:06,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 — Loss: 0.4589 | Accuracy: 0.6923 | F1-macro: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:45<00:00,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 — Loss: 0.4382 | Accuracy: 0.6538 | F1-macro: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)  # ← attention, le champ correct ici\n",
    "\n",
    "        logits = model(input_ids, attention_mask)  # [batch, 6]\n",
    "        loss = criterion(logits, labels)           # labels : [batch] (entiers 0–5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {total_loss/len(train_loader):.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | F1-macro: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9d48432-c1f9-47b2-9e3a-3595019cc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"camembert_cnn_lstm_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ede50c6-b209-4d48-a253-f8a97e5d8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_theme(text, model, tokenizer, device, label_encoder=None):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs['input_ids'], inputs['attention_mask'])  # shape: [1, 6]\n",
    "\n",
    "    prediction_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    if label_encoder is not None:\n",
    "        prediction_label = label_encoder.inverse_transform([prediction_idx])[0]\n",
    "        return prediction_label, prediction_idx\n",
    "    else:\n",
    "        return prediction_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80e4abfa-becb-4fdb-95dc-d8488ff33632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   actualité       0.78      0.86      0.82        21\n",
      "     analyse       0.43      0.55      0.48        11\n",
      "     culture       0.78      0.67      0.72        21\n",
      "   politique       0.57      0.52      0.54        25\n",
      "\n",
      "    accuracy                           0.65        78\n",
      "   macro avg       0.64      0.65      0.64        78\n",
      "weighted avg       0.66      0.65      0.65        78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06245628-ff2a-4d6f-b2ea-707b0c025ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Forcer la conversion en string et remplacer les NaN\n",
    "        text = str(self.df.loc[idx, \"texte\"]) if pd.notna(self.df.loc[idx, \"texte\"]) else \"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361041ca-0004-4712-9cc3-d80c2b984fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/data_clean.csv\")\n",
    "df.dropna(subset=['texte'], inplace=True)\n",
    "df['texte'] = df['texte'].str.lower()\n",
    "inference_dataset = InferenceDataset(df, tokenizer)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aced732a-c99a-4633-91d1-0bc9f066983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [03:55<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(inference_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)            # [batch, num_classes]\n",
    "        probs = softmax(logits, dim=1)                       # [batch, num_classes]\n",
    "\n",
    "        pred_classes = torch.argmax(probs, dim=1)            # [batch]\n",
    "        max_probs = torch.max(probs, dim=1).values           # [batch]\n",
    "\n",
    "        all_preds.extend(pred_classes.cpu().numpy())\n",
    "        all_probs.extend(max_probs.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "694a34e3-1249-42ec-9a81-6f364a91a79c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (11970) does not match length of index (11974)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtexte_total\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtitre\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m + df[\u001b[33m\"\u001b[39m\u001b[33mtexte\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 4. Ajouter les prédictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtheme_pred_encoded\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = all_preds\n\u001b[32m     14\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtheme_pred\u001b[39m\u001b[33m\"\u001b[39m] = label_encoder.inverse_transform(all_preds)\n\u001b[32m     15\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m] = all_probs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/core/frame.py:4311\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4308\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4310\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/core/frame.py:4524\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4515\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4516\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4517\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4522\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4524\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4527\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4528\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4529\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4530\u001b[39m     ):\n\u001b[32m   4531\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4532\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/core/frame.py:5266\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5266\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5267\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5269\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5270\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5273\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5274\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/core/common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (11970) does not match length of index (11974)"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Charger et nettoyer le corpus\n",
    "df = pd.read_csv(\"Data/data_clean.csv\")\n",
    "df.dropna(subset=[\"texte\"], inplace=True)\n",
    "df[\"texte\"] = df[\"texte\"].astype(str).str.lower()\n",
    "\n",
    "# 2. Fusionner avec les annotations manuelles (df_themes)\n",
    "df = df.merge(df_themes, on=\"identifiant\", how=\"left\")  # assure-toi que 'identifiant' existe dans les 2\n",
    "\n",
    "# 3. Construire texte_total\n",
    "df[\"texte_total\"] = df[\"titre\"].fillna(\"\") + \" \" + df[\"texte\"].fillna(\"\")\n",
    "\n",
    "# 4. Appliquer les prédictions uniquement aux lignes valides\n",
    "df_inference = df[df[\"texte_total\"].notna()].reset_index(drop=True)\n",
    "df_inference[\"theme_pred_encoded\"] = all_preds\n",
    "df_inference[\"theme_pred\"] = label_encoder.inverse_transform(all_preds)\n",
    "df_inference[\"confidence\"] = all_probs\n",
    "\n",
    "# Réinjecter les résultats dans df\n",
    "df.loc[df_inference.index, [\"theme_pred_encoded\", \"theme_pred\", \"confidence\"]] = df_inference[[\"theme_pred_encoded\", \"theme_pred\", \"confidence\"]].values\n",
    "\n",
    "# 5. Harmoniser les catégories manuelles\n",
    "df[\"theme\"] = df[\"theme\"].replace({\n",
    "    \"tribune\": \"analyse\",\n",
    "    \"société\": \"politique\"\n",
    "})\n",
    "\n",
    "# 6. Marquer les lignes annotées\n",
    "df[\"true_pred\"] = df[\"theme\"].notna()\n",
    "\n",
    "# 7. Construire theme_final\n",
    "df[\"theme_final\"] = df[\"theme\"].fillna(df[\"theme_pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f252587-5dbb-4ae5-972b-00f607ab5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"confidence\"]>= 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff52ae7-f664-412a-a087-0b767a199620",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_counts = df[\"theme_pred\"].value_counts(normalize=True) * 100\n",
    "print(theme_counts.round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770a5e2-6a28-4000-a5a5-19103c03d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced187b-20eb-4e53-9a01-b0583c5b9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['theme_final']=='actualité']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b166b-f10b-4feb-82db-1661c20757db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/actualite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf3b04-583d-4b49-a6b6-59e3a15f679c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb9b0a8",
   "metadata": {},
   "source": [
    "## 🔁 Pipeline post-entraînement : préparation, prédiction, fusion et finalisation des thèmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Charger et nettoyer le corpus\n",
    "df = pd.read_csv(\"Data/data_clean.csv\")\n",
    "df.dropna(subset=[\"texte\"], inplace=True)\n",
    "df[\"texte\"] = df[\"texte\"].astype(str).str.lower()\n",
    "\n",
    "# 2. Fusionner avec les annotations manuelles (df_themes)\n",
    "df = df.merge(df_themes, on=\"identifiant\", how=\"left\")  # assure-toi que 'identifiant' existe dans les 2\n",
    "\n",
    "# 3. Construire texte_total\n",
    "df[\"texte_total\"] = df[\"titre\"].fillna(\"\") + \" \" + df[\"texte\"].fillna(\"\")\n",
    "\n",
    "# 4. Préparer les données d'inférence\n",
    "df_inference = df[df[\"texte_total\"].notna()].reset_index(drop=True)\n",
    "\n",
    "# 5. Appliquer le modèle entraîné\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "with torch.no_grad():\n",
    "    inference_dataset = InferenceDataset(df_inference, tokenizer)\n",
    "    inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    for batch in inference_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        probs = softmax(logits, dim=1)\n",
    "        pred_classes = torch.argmax(probs, dim=1)\n",
    "        max_probs = torch.max(probs, dim=1).values\n",
    "\n",
    "        all_preds.extend(pred_classes.cpu().numpy())\n",
    "        all_probs.extend(max_probs.cpu().numpy())\n",
    "\n",
    "# 6. Injecter les prédictions dans df_inference\n",
    "df_inference[\"theme_pred_encoded\"] = all_preds\n",
    "df_inference[\"theme_pred\"] = label_encoder.inverse_transform(all_preds)\n",
    "df_inference[\"confidence\"] = all_probs\n",
    "\n",
    "# 7. Réintégrer dans df global\n",
    "df.loc[df_inference.index, [\"theme_pred_encoded\", \"theme_pred\", \"confidence\"]] = df_inference[[\"theme_pred_encoded\", \"theme_pred\", \"confidence\"]].values\n",
    "\n",
    "# 8. Harmoniser les catégories annotées manuelles\n",
    "df[\"theme\"] = df[\"theme\"].replace({\n",
    "    \"tribune\": \"analyse\",\n",
    "    \"société\": \"politique\"\n",
    "})\n",
    "\n",
    "# 9. Marquer les articles annotés manuellement\n",
    "df[\"true_pred\"] = df[\"theme\"].notna()\n",
    "\n",
    "# 10. Créer colonne finale : annotation > prédiction\n",
    "df[\"theme_final\"] = df[\"theme\"].fillna(df[\"theme_pred\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
